{
  "spec_id": "TTL-A2",
  "title": "Dataset Validation, Splitting and Metrics Logging",
  "version": "v2",
  "stage": "A2",
  "lab": "tiny-transformer-lab",
  "goal": "Extend dataset validation to generate manifest, compute detailed statistics, perform deterministic splits, and log all results to MLflow and JSONL metrics files.",
  "scope": {
    "inputs": [
      "Validated datasets from toy-lang-lab in JSONL or Parquet format",
      "Schema YAML from conf/data/sample_dataset.yaml",
      "Optional config.yaml describing split ratios and seed"
    ],
    "outputs": [
      "dataset.manifest.json (paths, splits, hashes, seed, grammar_rev)",
      "metrics.jsonl (stream of validation and split metrics)",
      "MLflow run with logged metrics and artifacts"
    ]
  },
  "requirements": {
    "cli": {
      "command": "data:process",
      "args": [
        "--in <path to validated dataset>",
        "--schema <path to YAML schema>",
        "--format JSONL|PARQUET",
        "--splits train=0.8 dev=0.1 test=0.1",
        "--seed <int>",
        "--log-to-mlflow"
      ],
      "behavior": [
        "Reuses validate_dataset() from A1 to confirm dataset integrity",
        "Computes unique row count, per-task counts, field coverage, n-gram frequency, noise-rate",
        "Performs deterministic split using given seed and ratios",
        "Saves new files train.jsonl, dev.jsonl, test.jsonl to out/",
        "Builds dataset.manifest.json with all metadata and sha256 of each split",
        "Logs ValidationReport and split metrics to MLflow and metrics.jsonl"
      ]
    },
    "manifest_format": {
      "example": {
        "dataset_id": "toy-v1",
        "grammar_rev": "c24837e4...",
        "seed": 13,
        "splits": {
          "train": {"path": "data/train.jsonl", "rows": 800, "sha256": "abc..."},
          "dev": {"path": "data/dev.jsonl", "rows": 100, "sha256": "def..."},
          "test": {"path": "data/test.jsonl", "rows": 100, "sha256": "ghi..."}
        },
        "format": "JSONL",
        "created_at": "2025-10-23T12:00:00Z",
        "schema_path": "conf/data/sample_dataset.yaml"
      }
    },
    "metrics_logging": {
      "rules": [
        "Use MetricsWriter (JSONL) for local logs",
        "Use MLflow API for experiment tracking; one run per dataset",
        "Logged metrics: rows_total, valid_ratio, task_distribution, noise_rate, duration_sec",
        "Artifacts: manifest.json, dataset_stats.json"
      ]
    },
    "statistics": {
      "features": [
        "row counts per split",
        "frequency of tasks and labels",
        "field completeness (% non-null)",
        "n-gram vocabulary size per task",
        "basic text length histograms (mean, std, min, max)"
      ]
    }
  },
  "ARD": {
    "purpose": "Architect data pipeline for post-validation metrics and split generation.",
    "components": {
      "CLI": "ttlab/cli/data_process.py",
      "Core": "ttlab/core/process.py (splitting, manifest, stats)",
      "Validator": "ttlab/core/validate.py (reuse from A1)",
      "Metrics": "ttlab/utils/metrics_writer.py",
      "MLflow": "ttlab/utils/mlflow_utils.py",
      "Schema": "conf/data/sample_dataset.yaml"
    },
    "dataflow": [
      "CLI → load dataset → validate → compute stats → perform splits → write manifest → log metrics → flush to MLflow"
    ]
  },
  "ADR": {
    "ADR-0004": {
      "decision": "Use deterministic random splits with numpy.random.Generator(seed)",
      "status": "accepted",
      "rationale": "Ensures reproducible dataset partitions across runs."
    },
    "ADR-0005": {
      "decision": "Store all derived files under out/ directory with hashed filenames",
      "status": "accepted",
      "rationale": "Allows easy cache invalidation and integrity checking."
    },
    "ADR-0006": {
      "decision": "Integrate MLflow logging for dataset-level metrics",
      "status": "accepted",
      "rationale": "Maintains traceability and unified tracking with model experiments."
    }
  },
  "DoD": {
    "checklist": [
      "CLI command data:process implemented and callable",
      "Manifest JSON generated with correct fields",
      "Split files created deterministically from seed",
      "Detailed statistics computed and saved",
      "Metrics logged to MLflow and metrics.jsonl",
      "Exit codes follow ExitCode enum",
      "Unit, integration, e2e tests pass",
      "Documentation updated"
    ]
  },
  "tests": {
    "unit": [
      "test_split_determinism()",
      "test_compute_statistics_correctness()",
      "test_manifest_creation_fields()"
    ],
    "integration": [
      "test_cli_data_process_success()",
      "test_cli_data_process_invalid_schema()"
    ],
    "e2e": [
      "test_end_to_end_process_and_manifest_smoke()"
    ]
  },
  "clear_metrics": {
    "coverage": ">=90%",
    "avg_split_latency_ms": "<=5",
    "manifest_integrity": "100%",
    "mlflow_logging_success": "100%"
  },
  "quality_gates": {
    "pre_commit": ["ruff", "black", "mypy"],
    "pre_merge": ["pytest --cov"],
    "pre_release": ["pytest -m e2e-smoke"]
  },
  "traceability": {
    "chain": "Dataset → Validation → Split → Manifest → Metrics → MLflow run_id",
    "recorded_metrics": [
      "rows_total",
      "rows_valid",
      "rows_per_split",
      "task_distribution",
      "duration_sec"
    ]
  },
  "artifacts": {
    "python": [
      "ttlab/cli/data_process.py",
      "ttlab/core/process.py"
    ],
    "yaml": ["conf/data/sample_dataset.yaml"],
    "json": [
      "out/dataset.manifest.json",
      "out/dataset_stats.json"
    ],
    "tests": [
      "tests/unit/test_process.py",
      "tests/integration/test_cli_process.py"
    ],
    "docs": ["spec/A2/spec_A2.json.v2"]
  },
  "timeline": {
    "estimated_duration_days": 6,
    "dependencies": ["TTL-A1 completed", "toy-lang-lab A2 dataset generation stable"]
  },
  "maintainers": [
    "Andrei (lead dev, TTL)",
    "GPT-5 (assistant architect)"
  ]
}
